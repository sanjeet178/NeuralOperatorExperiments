[2026-01-23 23:12:33] INFO: Loading cached tensors:
data/x_darcy_train_16.pt
data/y_darcy_train_16.pt
[2026-01-23 23:12:33] INFO: xTrain.shape, yTrain.shape: torch.Size([1000, 3, 16, 16]), torch.Size([1000, 1, 16, 16])
[2026-01-23 23:12:33] INFO: Model architecture: FNO(
  (lift): Sequential(
    (0): Linear(in_features=3, out_features=6, bias=True)
    (1): GELU(approximate='none')
  )
  (projection): Sequential(
    (0): Linear(in_features=6, out_features=1, bias=True)
    (1): GELU(approximate='none')
  )
  (fnoBlock): ModuleList(
    (0): OperatorBlock(
      (w): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))
      (spectralConv): SpectralConv2d()
    )
  )
)
[2026-01-23 23:12:33] INFO: Total trainable parameters in the model: 2989
[2026-01-23 23:12:33] INFO: Training has begun !!!!
[2026-01-23 23:12:35] INFO: epoch = 0, loss = 11.602910041809082
[2026-01-23 23:12:36] INFO: epoch = 10, loss = 5.2473273277282715
[2026-01-23 23:12:36] INFO: epoch = 20, loss = 0.16508379578590393
[2026-01-23 23:12:37] INFO: epoch = 30, loss = 0.05664200708270073
[2026-01-23 23:12:37] INFO: epoch = 40, loss = 0.027333984151482582
[2026-01-23 23:12:38] INFO: epoch = 50, loss = 0.02292642556130886
[2026-01-23 23:12:39] INFO: epoch = 60, loss = 0.02061423845589161
[2026-01-23 23:12:39] INFO: epoch = 70, loss = 0.01858808472752571
[2026-01-23 23:12:40] INFO: epoch = 80, loss = 0.016650859266519547
[2026-01-23 23:12:40] INFO: epoch = 90, loss = 0.01632339507341385
[2026-01-23 23:12:41] INFO: epoch = 100, loss = 0.016001390293240547
[2026-01-23 23:12:42] INFO: epoch = 110, loss = 0.015663670375943184
[2026-01-23 23:12:42] INFO: epoch = 120, loss = 0.015234062448143959
[2026-01-23 23:12:43] INFO: epoch = 130, loss = 0.014837860129773617
[2026-01-23 23:12:43] INFO: epoch = 140, loss = 0.014502442441880703
[2026-01-23 23:12:44] INFO: epoch = 150, loss = 0.014161153696477413
[2026-01-23 23:12:44] INFO: epoch = 160, loss = 0.013765540905296803
[2026-01-23 23:12:45] INFO: epoch = 170, loss = 0.013477214612066746
[2026-01-23 23:12:45] INFO: epoch = 180, loss = 0.013181788846850395
[2026-01-23 23:12:46] INFO: epoch = 190, loss = 0.012964152731001377
[2026-01-23 23:12:46] INFO: epoch = 200, loss = 0.01272223237901926
[2026-01-23 23:12:47] INFO: epoch = 210, loss = 0.012535332702100277
[2026-01-23 23:12:47] INFO: epoch = 220, loss = 0.012373508885502815
[2026-01-23 23:12:48] INFO: epoch = 230, loss = 0.012197336181998253
[2026-01-23 23:12:48] INFO: epoch = 240, loss = 0.012044680304825306
[2026-01-23 23:12:49] INFO: epoch = 250, loss = 0.011883356608450413
[2026-01-23 23:12:50] INFO: epoch = 260, loss = 0.011757965199649334
[2026-01-23 23:12:50] INFO: epoch = 270, loss = 0.011626694351434708
[2026-01-23 23:12:51] INFO: epoch = 280, loss = 0.01152513176202774
[2026-01-23 23:12:51] INFO: epoch = 290, loss = 0.011438610032200813
[2026-01-23 23:12:52] INFO: epoch = 300, loss = 0.011351766996085644
[2026-01-23 23:12:52] INFO: epoch = 310, loss = 0.011280507780611515
[2026-01-23 23:12:53] INFO: epoch = 320, loss = 0.01121570821851492
[2026-01-23 23:12:53] INFO: epoch = 330, loss = 0.011155694723129272
[2026-01-23 23:12:54] INFO: epoch = 340, loss = 0.01110382191836834
[2026-01-23 23:12:54] INFO: epoch = 350, loss = 0.011054725386202335
[2026-01-23 23:12:55] INFO: epoch = 360, loss = 0.011008311063051224
[2026-01-23 23:12:55] INFO: epoch = 370, loss = 0.010963606648147106
[2026-01-23 23:12:56] INFO: epoch = 380, loss = 0.010926040820777416
[2026-01-23 23:12:57] INFO: epoch = 390, loss = 0.01089813094586134
[2026-01-23 23:12:58] INFO: epoch = 400, loss = 0.010864969342947006
[2026-01-23 23:12:59] INFO: epoch = 410, loss = 0.010831312276422977
[2026-01-23 23:13:00] INFO: epoch = 420, loss = 0.010804574005305767
[2026-01-23 23:13:01] INFO: epoch = 430, loss = 0.010772294364869595
[2026-01-23 23:13:01] INFO: epoch = 440, loss = 0.010742267593741417
[2026-01-23 23:13:02] INFO: epoch = 450, loss = 0.010716439224779606
[2026-01-23 23:13:03] INFO: epoch = 460, loss = 0.010692482814192772
[2026-01-23 23:13:04] INFO: epoch = 470, loss = 0.010669207200407982
[2026-01-23 23:13:04] INFO: epoch = 480, loss = 0.010647621937096119
[2026-01-23 23:13:05] INFO: epoch = 490, loss = 0.010621696710586548
[2026-01-23 23:13:06] INFO: epoch = 500, loss = 0.010599927976727486
[2026-01-23 23:13:07] INFO: epoch = 510, loss = 0.010577070526778698
[2026-01-23 23:13:08] INFO: epoch = 520, loss = 0.010556366294622421
[2026-01-23 23:13:08] INFO: epoch = 530, loss = 0.010537595488131046
[2026-01-23 23:13:09] INFO: epoch = 540, loss = 0.010514301247894764
[2026-01-23 23:13:10] INFO: epoch = 550, loss = 0.010493776760995388
[2026-01-23 23:13:11] INFO: epoch = 560, loss = 0.010475855320692062
[2026-01-23 23:13:11] INFO: epoch = 570, loss = 0.010455700568854809
[2026-01-23 23:13:12] INFO: epoch = 580, loss = 0.010438240133225918
[2026-01-23 23:13:13] INFO: epoch = 590, loss = 0.01042195875197649
[2026-01-23 23:13:13] INFO: Inference has begun !!!!
[2026-01-23 23:13:13] INFO: Loading cached tensors:
data/x_darcy_test_32.pt
data/y_darcy_test_32.pt
[2026-01-23 23:13:18] INFO: Inference has ended !!!!
